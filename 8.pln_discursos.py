# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1trWBXxPwtIctyKJmLCUfYm2dnvCCJyGM
"""

import pandas as pd
import spacy
from collections import Counter

# Cargar los datos
discursos = pd.read_csv("df_entrevistas_limpio.csv")
discursos = discursos.drop(columns=['...1'])


# Inicializar Spacy con el modelo 'es_core_news_sm'
spacy.cli.download("es_core_news_sm")
nlp = spacy.load('es_core_news_sm')

parsedtxt = []
for texto in discursos['texto']:
    doc = nlp(texto)
    adjetivos = [token.text for token in doc if token.pos_ == 'ADJ']
    verbos = [token.text for token in doc if token.pos_ == 'VERB']
    sustantivos = [token.text for token in doc if token.pos_ == 'NOUN']
    personas = [token.text for token in doc if token.pos_ == 'PER']
    organizaciones = [token.text for token in doc if token.pos_ == 'ORG']
    lugares= [token.text for token in doc if token.pos_ == 'LOC']

    frecuencia_adjetivos = Counter(adjetivos)
    frecuencia_verbos = Counter(verbos)
    frecuencia_sustantivos = Counter(sustantivos)
    frecuencia_personas = Counter(personas)
    frecuencia_organizaciones = Counter(organizaciones)
    frecuencia_lugares = Counter(lugares)

    parsed = {
        'adjetivos': frecuencia_adjetivos,
        'verbos': frecuencia_verbos,
        'sustantivos': frecuencia_sustantivos,
        "personas": frecuencia_personas,
        "organizaciones": frecuencia_organizaciones,
        "lugares": frecuencia_lugares
    }
    parsedtxt.append(parsed)

discursos_parsed = pd.concat([discursos, pd.DataFrame(parsedtxt)], axis=1)
discursos_parsed.to_csv('discursos_parsed.csv', index=False)